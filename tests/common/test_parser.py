import pytest
from dlt.common.sources import DLT_METADATA_FIELD, with_table_name

from dlt.common.utils import digest128, uniq_id
from dlt.common.schema import Schema

from dlt.common.normalizers.json.relational import _flatten, _get_child_row_hash, _unpack_row, normalize

from tests.utils import create_schema_with_name

@pytest.fixture
def schema() -> Schema:
    return Schema("default")


def test_flatten_fix_field_name() -> None:
    row = {
        "f-1": "!  30",
        "f 2": [],
        "f!3": {
            "f4": "a",
            "f-5": "b",
            "f*6": {
                "c": 7,
                "c v": 8,
                "c x": []
            }
        }
    }
    flattened_row = _flatten("mock_table", row)
    assert "f_1" in flattened_row
    assert "f_2" in flattened_row
    assert "f_3__f4" in flattened_row
    assert "f_3__f_5" in flattened_row
    assert "f_3__f_6__c" in flattened_row
    assert "f_3__f_6__c_v" in flattened_row
    assert "f_3__f_6__c_x" in flattened_row
    assert "f_3" not in flattened_row


def test_preserve_complex_value() -> None:
    row_1 = {
        "value": 1
    }
    flattened_row = _flatten("event_slot", row_1)
    assert flattened_row["value"] == 1

    row_2 = {
        "value": {"complex": True}
    }
    flattened_row = _flatten("event_slot", row_2)
    assert flattened_row["value"] == row_2["value"]
    assert flattened_row["value__complex"] is True


def test_child_table_linking(schema: Schema) -> None:
    row = {
        "f": [{
            "l": ["a", "b", "c"],
            "v": 120,
            "o": [{"a": 1}, {"a": 2}]
        }]
    }
    # request _root_hash propagation but use None to get generated record_hash
    rows = list(_unpack_row(schema, row, {"_root_hash": None}, "table"))
    # should have 7 entries (root + level 1 + 3 * list + 2 * object)
    assert len(rows) == 7
    # root elem will not have a root hash if not explicitly added, "extend" is added only to child
    root = next(t for t in rows if t[0] == "table")[1]
    assert "_root_hash" not in root
    assert "_parent_hash" not in root
    assert "_pos" not in root
    # record hash will be autogenerated
    assert "_record_hash" in root
    row_id = root["_record_hash"]

    # all child entries must have _root_hash == row_id
    assert all(e[1]["_root_hash"] == row_id for e in rows if e[0] != "table")
    # all child entries must have _record_hash
    assert all("_record_hash" in e[1] for e in rows if e[0] != "table")
    # all child entries must have parent hash and pos
    assert all("_parent_hash" in e[1] for e in rows if e[0] != "table")
    assert all("_pos" in e[1] for e in rows if e[0] != "table")
    # filter 3 entries with list
    list_rows = [t for t in rows if t[0] == "table__f__l"]
    assert len(list_rows) == 3
    # get parent for list
    f_row_v = next(t for t in rows if t[0] == "table__f")[1]
    # parent of "f" must be row_id
    assert f_row_v["_parent_hash"] == row_id
    # all elems in the list must have proper parent
    assert all(e[1]["_parent_hash"] == f_row_v["_record_hash"] for e in list_rows)
    # all values are there
    assert [e[1]["value"] for e in list_rows] == ["a", "b", "c"]


def test_child_table_linking_primary_key(schema: Schema) -> None:
    row = {
        "id": "level0",
        "f": [{
            "id": "level1",
            "l": ["a", "b", "c"],
            "v": 120,
            "o": [{"a": 1}, {"a": 2}]
        }]
    }
    schema._hints = {"primary_key": ["^id$"]}
    schema._compile_regexes()

    rows = list(_unpack_row(schema, row, {"_root_hash": None}, "table"))
    root = next(t for t in rows if t[0] == "table")[1]
    # record hash must be derived from natural key
    assert root["_record_hash"] == digest128("level0")

    # table at "f"
    t_f = next(t for t in rows if t[0] == "table__f")[1]
    assert t_f["_record_hash"] == digest128("level1")
    # we use primary key to link to parent
    assert "_parent_hash" not in t_f
    assert "_pos" not in t_f
    assert "_root_hash" not in t_f

    list_rows = [t for t in rows if t[0] == "table__f__l"]
    assert(all(e[1]["_parent_hash"] == digest128("level1") for e in list_rows))
    obj_rows = [t for t in rows if t[0] == "table__f__o"]
    assert(all(e[1]["_parent_hash"] == digest128("level1") for e in obj_rows))


def test_child_table_linking_compound_primary_key(schema: Schema) -> None:
    row = {
        "id": "level0",
        "offset": 12102.45,
        "f": [{
            "id": "level1",
            "item_no": 8129173987192873,
            "l": ["a", "b", "c"],
            "v": 120,
            "o": [{"a": 1}, {"a": 2}]
        }]
    }
    schema._hints = {"primary_key": ["^id$", "^offset$", "^item_no$"]}
    schema._compile_regexes()

    rows = list(_unpack_row(schema, row, {}, "table"))
    root = next(t for t in rows if t[0] == "table")[1]
    # record hash must be derived from natural key
    assert root["_record_hash"] == digest128("level0_12102.45")
    t_f = next(t for t in rows if t[0] == "table__f")[1]
    assert t_f["_record_hash"] == digest128("level1_8129173987192873")


def test_list_position(schema: Schema) -> None:
    row = {
        "f": [{
            "l": ["a", "b", "c"],
            "v": 120,
            "lo": [{"e": "a"}, {"e": "b"}, {"e":"c"}]
        }]
    }
    rows = list(_unpack_row(schema, row, {}, "table"))
    # root has no pos
    root = [t for t in rows if t[0] == "table"][0][1]
    assert "_pos" not in root

    # all other have pos
    others = [t for t in rows if t[0] != "table"]
    assert all("_pos" in e[1] for e in others)

    # f_l must be ordered as it appears in the list
    for pos, elem in enumerate(["a", "b", "c"]):
        row = next(t[1] for t in rows if t[0] == "table__f__l" and t[1]["value"] == elem)
        assert row["_pos"] == pos

    # f_lo must be ordered - list of objects
    for pos, elem in enumerate(["a", "b", "c"]):
        row = next(t[1] for t in rows if t[0] == "table__f__lo" and t[1]["e"] == elem)
        assert row["_pos"] == pos


def test_child_row_deterministic_hash(schema: Schema) -> None:
    row_id = uniq_id()
    # directly set record hash so it will be adopted in unpacker as top level hash
    row = {
        "_record_hash": row_id,
        "f": [{
            "l": ["a", "b", "c"],
            "v": 120,
            "lo": [{"e": "a"}, {"e": "b"}, {"e":"c"}]
        }]
    }
    rows = list(_unpack_row(schema, row, {"_root_hash": None}, "table"))
    children = [t for t in rows if t[0] != "table"]
    # all hashes must be different
    distinct_hashes = set([ch[1]["_record_hash"] for ch in children])
    assert len(distinct_hashes) == len(children)

    # compute hashes for all children
    for table, ch in children:
        expected_hash = digest128(f"{ch['_parent_hash']}_{table}_{ch['_pos']}")
        assert ch["_record_hash"] == expected_hash

    # direct compute one of the
    el_f = next(t[1] for t in rows if t[0] == "table__f" and t[1]["_pos"] == 0)
    f_lo_p2 = next(t[1] for t in rows if t[0] == "table__f__lo" and t[1]["_pos"] == 2)
    assert f_lo_p2["_record_hash"] == digest128(f"{el_f['_record_hash']}_table__f__lo_2")

    # same data with same table and row_id
    rows_2 = list(_unpack_row(schema, row, {"_root_hash": "root_hash"}, "table"))
    children_2 = [t for t in rows_2 if t[0] != "table"]
    # corresponding hashes must be identical
    assert all(ch[0][1]["_record_hash"] == ch[1][1]["_record_hash"] for ch in zip(children, children_2))

    # change parent table and all child hashes must be different
    rows_4 = list(_unpack_row(schema, row, {"_root_hash": "root_hash"}, "other_table"))
    children_4 = [t for t in rows_4 if t[0] != "other_table"]
    assert all(ch[0][1]["_record_hash"] != ch[1][1]["_record_hash"] for ch in zip(children, children_4))

    # change parent hash and all child hashes must be different
    row["_record_hash"] = uniq_id()
    rows_3 = list(_unpack_row(schema, row, {"_root_hash": "root_hash"}, "table"))
    children_3 = [t for t in rows_3 if t[0] != "table"]
    assert all(ch[0][1]["_record_hash"] != ch[1][1]["_record_hash"] for ch in zip(children, children_3))


def test_keeps_record_hash(schema: Schema) -> None:
    h = uniq_id()
    row = {
        "a": "b",
        "_record_hash": h
    }
    rows = list(_unpack_row(schema, row, {"_root_hash": "root_hash"}, "table"))
    root = [t for t in rows if t[0] == "table"][0][1]
    assert root["_record_hash"] == h


def test_propagate_context(schema: Schema) -> None:
    row = {"level": 1, "list": ["a", "b", "c"], "comp": [{"_timestamp": "a"}]}
    rows = list(_unpack_row(schema, row, {"_timestamp": 1238.9, "_dist_key": "SENDER_3000"}, "table"))
    # context is not added to root element
    root = next(t for t in rows if t[0] == "table")[1]
    assert "_timestamp" not in root
    assert "_dist_key" not in root
    # the original _timestamp field will be overwritten in children
    assert all(e[1]["_timestamp"] == 1238.9 and e[1]["_dist_key"] == "SENDER_3000" for e in rows if e[0] != "table")


def test_preserves_complex_types_list(schema: Schema) -> None:
    row = {
        "value": ["from", {"complex": True}]
    }
    rows = list(_unpack_row(schema, row, {}, "event_slot"))
    assert len(rows) == 3
    # this is event_slot
    assert rows[-1][1]["value"] == row["value"]


def test_extract_with_table_name_meta() -> None:
    row = {
        "id": "817949077341208606",
        "type": 4,
        "name": "Moderation",
        "position": 0,
        "flags": 0,
        "parent_id": None,
        "guild_id": "815421435900198962",
        "permission_overwrites": []
    }
    # force table name
    rows = list(
        normalize(create_schema_with_name("discord"), with_table_name(row, "channel"), "load_id")
    )
    # table is channel
    assert rows[0][0] == "channel"
    unpacked_row = rows[0][1]
    # __dlt_meta must be removed must be removed
    assert DLT_METADATA_FIELD not in unpacked_row
    assert unpacked_row["guild_id"] == "815421435900198962"
    assert "_record_hash" in unpacked_row
    assert unpacked_row["_load_id"] == "load_id"


def test_parse_with_primary_key() -> None:
    schema = create_schema_with_name("discord")
    schema._hints = {"primary_key": ["^id$"]}
    schema._compile_regexes()
    row = {
        "id": "817949077341208606",
        "w_id":[{
            "id": 9128918293891111,
            "wo_id": [1, 2, 3]
            }]
    }
    rows = list(normalize(schema, row, "load_id"))
    # get root
    root = next(t[1] for t in rows if t[0] == "discord")
    assert root["_record_hash"] == digest128("817949077341208606")
    assert "_parent_hash" not in root

    el_w_id = next(t[1] for t in rows if t[0] == "discord__w_id")
    # this also has primary key
    assert el_w_id["_record_hash"] == digest128("9128918293891111")
    assert "_root_hash" not in el_w_id
    assert "_parent_hash" not in el_w_id
    assert "_pos" not in el_w_id

    # this must have deterministic child key
    f_wo_id = next(t[1] for t in rows if t[0] == "discord__w_id__wo_id" and t[1]["_pos"] == 2)
    assert f_wo_id["value"] == 3
    assert f_wo_id["_root_hash"] == digest128("817949077341208606")
    assert f_wo_id["_parent_hash"] == digest128("9128918293891111")
    assert f_wo_id["_record_hash"] == _get_child_row_hash(digest128("9128918293891111"), "discord__w_id__wo_id", 2)


def test_keeps_none_values() -> None:
    row = {"a": None, "timestamp": 7}
    rows = list(normalize(create_schema_with_name("other"), row, "1762162.1212"))
    table_name = rows[0][0]
    assert table_name == "other"
    unpacked_row = rows[0][1]
    assert unpacked_row["a"] is None
    assert unpacked_row["_load_id"] == "1762162.1212"
